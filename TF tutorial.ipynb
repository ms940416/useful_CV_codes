{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2188bd526fa1>:27 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 [ 0.53401273] [ 0.11202575]\n",
      "20 [ 0.21537299] [ 0.24425496]\n",
      "40 [ 0.13128296] [ 0.28488496]\n",
      "60 [ 0.10848225] [ 0.29590163]\n",
      "80 [ 0.10229993] [ 0.29888874]\n",
      "100 [ 0.10062362] [ 0.29969868]\n",
      "120 [ 0.10016909] [ 0.29991832]\n",
      "140 [ 0.10004584] [ 0.29997787]\n",
      "160 [ 0.10001244] [ 0.29999399]\n",
      "180 [ 0.10000338] [ 0.29999837]\n",
      "200 [ 0.10000092] [ 0.29999956]\n"
     ]
    }
   ],
   "source": [
    "# View more python tutorial on my Youtube and Youku channel!!!\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# create data\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = x_data*0.1 + 0.3\n",
    "\n",
    "### create tensorflow structure start ###\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "biases = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "y = Weights*x_data + biases\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "### create tensorflow structure end ###\n",
    "\n",
    "sess = tf.Session()\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(Weights), sess.run(biases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n",
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# How to use Session\n",
    "#tensorflow的思考模式是每次sess.run()才会执行对应的语句\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3, 3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2]])\n",
    "product = tf.matmul(matrix1, matrix2)  # matrix multiply np.dot(m1, m2)\n",
    "\n",
    "# method 1\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method 2\n",
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print(result2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# How to define a variable in tensorflow\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "state = tf.Variable(0, name='counter')\n",
    "#print(state.name)\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "#must initialize all variable if you define them\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "#placeholder: 相当于一个占位置的变量，每次run session的时候可以传入不同的值，以字典的形式传入\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "#tf中一般只能处理float32\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "#乘法可以用mul或者multiply\n",
    "ouput = tf.multiply(input1, input2)\n",
    "\n",
    "#跟变量不同，placeholder不用initialize\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ouput, feed_dict={input1: [7.], input2: [2.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个神经层 \n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    #Weight不能初始相同，所以取随机值\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    #bias初始最好不为0\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    #矩阵乘法用matmul\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.77777778 -0.55555556 -0.33333333 -0.11111111  0.11111111\n",
      "  0.33333333  0.55555556  0.77777778  1.        ]\n",
      "[[-1.        ]\n",
      " [-0.77777778]\n",
      " [-0.55555556]\n",
      " [-0.33333333]\n",
      " [-0.11111111]\n",
      " [ 0.11111111]\n",
      " [ 0.33333333]\n",
      " [ 0.55555556]\n",
      " [ 0.77777778]\n",
      " [ 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.linspace(-1,1,10)\n",
    "print (x_data)\n",
    "x_data = np.linspace(-1,1,10)[:, np.newaxis]\n",
    "print (x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.353332\n",
      "0.0151757\n",
      "0.00763153\n",
      "0.0049365\n",
      "0.00426767\n",
      "0.00403341\n",
      "0.00392288\n",
      "0.00382434\n",
      "0.00375745\n",
      "0.00372582\n",
      "0.0036989\n",
      "0.0036767\n",
      "0.0036483\n",
      "0.00362506\n",
      "0.003605\n",
      "0.00358193\n",
      "0.00356376\n",
      "0.00354737\n",
      "0.00353565\n",
      "0.00352454\n"
     ]
    }
   ],
   "source": [
    "# 一个简单的编写例子\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data, 创建的是一个列向量\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]\n",
    "#mean是0，方差0.05，正态分布，datatype is the same as x_data\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "#记得要定义变量的type：float32\n",
    "#输入任意行数，一列\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediction and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# important step\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to see the step improvement\n",
    "        print(sess.run(loss, feed_dict={xs: x_data, ys: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "%matplotlib notebook\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1,1,300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                     reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# important step\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# plot the real data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "\n",
    "plt.show(block=False)\n",
    "#ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "    if i % 50 == 0:\n",
    "        # to visualize the result and improvement\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        # plot the prediction\n",
    "        lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "        plt.pause(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "0.1232\n",
      "0.6357\n",
      "0.7366\n",
      "0.7796\n",
      "0.807\n",
      "0.8225\n",
      "0.83\n",
      "0.8299\n",
      "0.8399\n",
      "0.8456\n",
      "0.8498\n",
      "0.8593\n",
      "0.8544\n",
      "0.8626\n",
      "0.8653\n",
      "0.8659\n",
      "0.87\n",
      "0.8689\n",
      "0.8699\n",
      "0.8709\n"
     ]
    }
   ],
   "source": [
    "#classification\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None,):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1,)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b,)\n",
    "    return outputs\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    #tf.cast is used to transform the datatype of a variable\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "prediction = add_layer(xs, 784, 10,  activation_function=tf.nn.softmax)\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropout\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# load data\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, layer_name, activation_function=None, ):\n",
    "    # add one more layer and return the output of this layer\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, )\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    # here to dropout\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b, )\n",
    "    tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "xs = tf.placeholder(tf.float32, [None, 64])  # 8x8\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# add output layer\n",
    "l1 = add_layer(xs, 64, 50, 'l1', activation_function=tf.nn.tanh)\n",
    "prediction = add_layer(l1, 50, 10, 'l2', activation_function=tf.nn.softmax)\n",
    "\n",
    "# the loss between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))  # loss\n",
    "tf.summary.scalar('loss', cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "# summary writer goes in here\n",
    "train_writer = tf.summary.FileWriter(\"logs/train\", sess.graph)\n",
    "test_writer = tf.summary.FileWriter(\"logs/test\", sess.graph)\n",
    "\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(500):\n",
    "    # here to determine the keeping probability\n",
    "    sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        # record loss\n",
    "        train_result = sess.run(merged, feed_dict={xs: X_train, ys: y_train, keep_prob: 1})\n",
    "        test_result = sess.run(merged, feed_dict={xs: X_test, ys: y_test, keep_prob: 1})\n",
    "        train_writer.add_summary(train_result, i)\n",
    "        test_writer.add_summary(test_result, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 784])/255.   # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "#-1 means ignore the original shape.then the output is 28*28*1\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
    "# print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\n",
    "h_pool1 = max_pool_2x2(h_conv1)                                         # output size 14x14x32\n",
    "\n",
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 7x7x64\n",
    "\n",
    "## fc1 layer ##\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "# the error between prediction and real data\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))       # loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "sess = tf.Session()\n",
    "# important step\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob: 0.5})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.rnn' has no attribute 'BasicLSTMCell'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9d5bce118951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-9d5bce118951>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(X, weights, biases)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBasicLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforget_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_is_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBasicLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[1;31m# lstm cell is divided into two parts (c_state, h_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0minit_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.contrib.rnn' has no attribute 'BasicLSTMCell'"
     ]
    }
   ],
   "source": [
    "# RNN for classification\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "This code is a modified version of the code from this link:\n",
    "https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "His code is a very good one for RNN beginners. Feel free to check it out.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# set random seed for comparing the two result calculations\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "# this is data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "# hyperparameters\n",
    "lr = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "\n",
    "n_inputs = 28   # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28    # time steps\n",
    "n_hidden_units = 128   # neurons in hidden layer\n",
    "n_classes = 10      # MNIST classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    # (28, 128)\n",
    "    'in': tf.Variable(tf.random_normal([n_inputs, n_hidden_units])),\n",
    "    # (128, 10)\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_units, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    # (128, )\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ])),\n",
    "    # (10, )\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes, ]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(X, weights, biases):\n",
    "    # hidden layer for input to cell\n",
    "    ########################################\n",
    "\n",
    "    # transpose the inputs shape from\n",
    "    # X ==> (128 batch * 28 steps, 28 inputs)\n",
    "    #-1can be used to infer number: https://www.tensorflow.org/api_docs/python/tf/reshape\n",
    "    X = tf.reshape(X, [-1, n_inputs])\n",
    "\n",
    "    # into hidden\n",
    "    # X_in = (128 batch * 28 steps, 128 hidden)\n",
    "    X_in = tf.matmul(X, weights['in']) + biases['in']\n",
    "    # X_in ==> (128 batch, 28 steps, 128 hidden)\n",
    "    X_in = tf.reshape(X_in, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "    # cell\n",
    "    ##########################################\n",
    "\n",
    "    # basic LSTM Cell.\n",
    "    if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden_units, forget_bias=1.0, state_is_tuple=True)\n",
    "    else:\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(n_hidden_units)\n",
    "    # lstm cell is divided into two parts (c_state, h_state)\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "    # You have 2 options for following step.\n",
    "    # 1: tf.nn.rnn(cell, inputs);\n",
    "    # 2: tf.nn.dynamic_rnn(cell, inputs).\n",
    "    # If use option 1, you have to modified the shape of X_in, go and check out this:\n",
    "    # https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    # In here, we go for option 2.\n",
    "    # dynamic_rnn receive Tensor (batch, steps, inputs) or (steps, batch, inputs) as X_in.\n",
    "    # Make sure the time_major is changed accordingly.\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, X_in, initial_state=init_state, time_major=False)\n",
    "\n",
    "    # hidden layer for output as the final results\n",
    "    #############################################\n",
    "    # results = tf.matmul(final_state[1], weights['out']) + biases['out']\n",
    "\n",
    "    # # or\n",
    "    # unpack to list [(batch, outputs)..] * steps\n",
    "    if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "        outputs = tf.unpack(tf.transpose(outputs, [1, 0, 2]))    # states is the last outputs\n",
    "    else:\n",
    "        outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "    results = tf.matmul(outputs[-1], weights['out']) + biases['out']    # shape = (128, 10)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # tf.initialize_all_variables() no long valid from\n",
    "    # 2017-03-02 if using tensorflow >= 0.12\n",
    "    if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "        init = tf.initialize_all_variables()\n",
    "    else:\n",
    "        init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    step = 0\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape([batch_size, n_steps, n_inputs])\n",
    "        sess.run([train_op], feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        })\n",
    "        if step % 20 == 0:\n",
    "            print(sess.run(accuracy, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys,\n",
    "        }))\n",
    "        step += 1\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
