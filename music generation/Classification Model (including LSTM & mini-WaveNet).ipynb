{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import all the dependency\n",
    "#utils include some functions that can help us to manitipulate midi file, it is written by https://github.com/brannondorsey/midi-rnn\n",
    "import os, argparse, time\n",
    "import utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.layers import Conv1D,GlobalMaxPooling1D\n",
    "OUTPUT_SIZE = 129 # 0-127 notes + 1 for rests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all gthe paramater we may use later on \n",
    "data_dir='data/midi'\n",
    "experiment_dir='experiments/default'\n",
    "window_size=50\n",
    "batch_size=32\n",
    "num_epochs=10\n",
    "dropout=0.2\n",
    "grad_clip=5.0\n",
    "n_jobs=1\n",
    "max_files_in_ram=25\n",
    "input_shape=(50,129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to build a 2-Layer LSTM model\n",
    "def LSTM_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(129))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to build a 1-D casual convolutional dilated model\n",
    "def dilated_casual_1D_conv_model(input_shape):\n",
    "    model = Sequential()\n",
    "    filters=[128, 128, 128, 128]\n",
    "    kernel_size=2\n",
    "    model.add(Conv1D(filters[0],\n",
    "                 kernel_size,\n",
    "                 input_shape=input_shape,\n",
    "                 padding='causal',\n",
    "                 dilation_rate=2,\n",
    "                 strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(filters[1],\n",
    "                 kernel_size,\n",
    "                 padding='causal',\n",
    "                 dilation_rate=4,\n",
    "                 strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(filters[2],\n",
    "                 kernel_size,\n",
    "                 padding='causal',\n",
    "                 dilation_rate=8,\n",
    "                 strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(filters[3],\n",
    "                 kernel_size,\n",
    "                 padding='causal',\n",
    "                 activation='relu',\n",
    "                 dilation_rate=8,\n",
    "                 strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.2))    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(129))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#denfine the callbacks function to monitor the trainning process\n",
    "def get_callbacks(experiment_dir, checkpoint_monitor='val_acc'):\n",
    "    \n",
    "    callbacks = []\n",
    "    \n",
    "    # save model checkpoints\n",
    "    filepath = os.path.join(experiment_dir, \n",
    "                            'checkpoints', \n",
    "                            'checkpoint-epoch_{epoch:03d}-val_acc_{val_acc:.3f}.hdf5')\n",
    "\n",
    "    callbacks.append(ModelCheckpoint(filepath, \n",
    "                                     monitor=checkpoint_monitor, \n",
    "                                     verbose=1, \n",
    "                                     save_best_only=False, \n",
    "                                     mode='max'))\n",
    "\n",
    "    callbacks.append(ReduceLROnPlateau(monitor='val_loss', \n",
    "                                       factor=0.5, \n",
    "                                       patience=3, \n",
    "                                       verbose=1, \n",
    "                                       mode='auto', \n",
    "                                       epsilon=0.0001, \n",
    "                                       cooldown=0, \n",
    "                                       min_lr=0))\n",
    "\n",
    "    callbacks.append(TensorBoard(log_dir=os.path.join(experiment_dir, 'tensorboard-logs'), \n",
    "                                histogram_freq=0, \n",
    "                                write_graph=True, \n",
    "                                write_images=False))\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # get paths to midi files in --data_dir\n",
    "    midi_files = [os.path.join(data_dir, path) \\\n",
    "                  for path in os.listdir(data_dir) \\\n",
    "                  if '.mid' in path or '.midi' in path]\n",
    "#print midi_files\n",
    "except OSError as e:\n",
    "    print(\"invalid path\")\n",
    "#check the data\n",
    "if len(midi_files) < 1:\n",
    "    print(\"no_enough data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Created experiment directory experiments\\02\n",
      "[*] Created checkpoint directory experiments\\02\\checkpoints\n",
      "[*] Created log directory experiments\\02\\tensorboard-logs\n"
     ]
    }
   ],
   "source": [
    "verbose=True\n",
    "experiment_dir = utils.create_experiment_dir(experiment_dir, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split the training and cross validation set\n",
    "val_split = 0.2 # use 20 percent for validation\n",
    "val_split_index = int(float(len(midi_files)) * val_split)\n",
    "#define the generator to generate the data in real-time\n",
    "train_generator = utils.get_data_generator(midi_files[0:val_split_index], \n",
    "                                           window_size=window_size,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_threads=n_jobs,\n",
    "                                           max_files_in_ram=max_files_in_ram)\n",
    "\n",
    "val_generator = utils.get_data_generator(midi_files[val_split_index:], \n",
    "                                         window_size=window_size,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_threads=n_jobs,\n",
    "                                         max_files_in_ram=max_files_in_ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 128)           132096    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 129)               16641     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 129)               0         \n",
      "=================================================================\n",
      "Total params: 280,321.0\n",
      "Trainable params: 280,321.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 50, 128)           33152     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 50, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 50, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 50, 128)           32896     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 129)               16641     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 129)               0         \n",
      "=================================================================\n",
      "Total params: 164,993.0\n",
      "Trainable params: 164,993.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#In our experiment, we have two model, one is 2-layer LSTM, another is dilated casual 1 D convolution\n",
    "#Details are included in the report\n",
    "#you can commond out one of the two code below to choose another model used in the trainning\n",
    "\n",
    "model = LSTM_model(input_shape)\n",
    "print(\"------------------------------------------------------------------------------------\")\n",
    "model = dilated_casual_1D_conv_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model...\n",
      "1Epoch 1/1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "#not enough time to rerun the model. So, no more running result later\n",
    "print('fitting model...')\n",
    "# this is a somewhat magic number which is the average number of length-20 windows\n",
    "# calculated from ~5K MIDI files from the Lakh MIDI Dataset.\n",
    "magic_number = 827\n",
    "start_time = time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(midi_files) * magic_number / batch_size, \n",
    "                    epochs=1,\n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=len(midi_files) * 0.2 * magic_number / batch_size,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_experiment_dir(experiment_dir):\n",
    "    if experiment_dir == 'experiments/default':\n",
    "        dirs_ = [os.path.join('experiments', d) for d in os.listdir('experiments') \\\n",
    "                 if os.path.isdir(os.path.join('experiments', d))]\n",
    "        experiment_dir = max(dirs_, key=os.path.getmtime)\n",
    "\n",
    "    if not os.path.exists(os.path.join(experiment_dir, 'model.json')):\n",
    "        print('no model')\n",
    "\n",
    "    return experiment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "midi_files = [ args.prime_file ] if args.prime_file else \\\n",
    "             [ os.path.join(args.data_dir, f) for f in os.listdir(args.data_dir) \\\n",
    "             if '.mid' in f or '.midi' in f ]\n",
    "\n",
    "experiment_dir = get_experiment_dir(args.experiment_dir)\n",
    "utils.log('Using {} as --experiment_dir'.format(experiment_dir), args.verbose)\n",
    "\n",
    "if not args.save_dir:\n",
    "    args.save_dir = os.path.join(experiment_dir, 'generated')\n",
    "\n",
    "if not os.path.isdir(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "    utils.log('Created directory {}'.format(args.save_dir), args.verbose)\n",
    "\n",
    "model = dilated_casual_1D_conv_model(input_shape)\n",
    "\n",
    "window_size = model.layers[0].get_input_shape_at(0)[1]\n",
    "seed_generator = utils.get_data_generator(midi_files, \n",
    "                                          window_size=window_size,\n",
    "                                          batch_size=32,\n",
    "                                          num_threads=1,\n",
    "                                          max_files_in_ram=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate 10 tracks using random seeds\n",
    "utils.log('Loading seed files...', args.verbose)\n",
    "X, y = seed_generator.next()\n",
    "generated = utils.generate(model, X, window_size, \n",
    "                           args.file_length, args.num_files, args.midi_instrument)\n",
    "# print(len(generated[0]))\n",
    "# #print(np.sum(generated,axis=1))\n",
    "for i, midi in enumerate(generated):\n",
    "    file = os.path.join(args.save_dir, '{}.mid'.format(i + 1))\n",
    "    midi.write(file.format(i + 1))\n",
    "    utils.log('wrote midi file to {}'.format(file), True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
